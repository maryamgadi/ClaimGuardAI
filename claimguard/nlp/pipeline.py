import json
import re
from langchain_ollama import OllamaLLM
from langchain_core.prompts import PromptTemplate

# 1. Initialisation de Llama 3 via LangChain et Ollama
# On met la 'temperature' √† 0 pour qu'il soit pr√©cis et factuel (pas cr√©atif)
llm = OllamaLLM(model="llama3", temperature=0.0)

def extract_entities(text: str) -> dict:
    """
    Extrait les informations cl√©s du texte OCR en utilisant l'intelligence de Llama 3.
    """
    # Si le texte est vide (ex: image blanche), on renvoie un dictionnaire vide
    if not text or not text.strip():
        return {}

    # 2. Le Prompt : On explique tr√®s clairement √† l'IA ce qu'elle doit faire
    prompt_template = """
    Tu es un assistant expert en extraction de donn√©es m√©dicales au Maroc (dossiers AMO/CNSS).
    Voici le texte brut extrait d'un document (ordonnance, facture, ou feuille de soins) par un OCR. 
    Le texte contient des fautes d'orthographe et de mise en page.

    --- TEXTE OCR ---
    {texte_ocr}
    -----------------

    T√ÇCHE :
    Extrais les informations suivantes et renvoie-les STRICTEMENT au format JSON. Ne dis rien d'autre, juste le JSON.
    - "patient_name" : Le nom et pr√©nom du patient. Corrige les fautes √©videntes (ex: 'Ee' -> 'El'). Enl√®ve les 'Mme', 'Dr', 'Patient'.
    - "doctor_name" : Le nom du m√©decin ou de la pharmacie.
    - "date" : La date du document.
    - "amount" : Le montant total √† payer (uniquement les chiffres, ex: "189.00").
    - "social_number" : Le num√©ro d'immatriculation CNSS (g√©n√©ralement 9 chiffres), si pr√©sent.
    - "medications" : Une liste contenant les noms des m√©dicaments (ex: ["XILOIAL", "Doliprane"]), si pr√©sent.

    R√àGLE ABSOLUE : Si une information est introuvable, mets `null` (ou `[]` pour les m√©dicaments). Ne rajoute aucun commentaire.

    R√âPONSE JSON :
    """

    # 3. Cr√©ation de la requ√™te
    prompt = PromptTemplate.from_template(prompt_template)
    requete_finale = prompt.format(texte_ocr=text)

    try:
        # 4. Appel √† Llama 3 (C'est ici que la magie op√®re !)
        print("üß† Llama 3 analyse le texte...")
        reponse_ia = llm.invoke(requete_finale)
        
        # 5. Nettoyage : On s'assure de ne r√©cup√©rer que la partie JSON de sa r√©ponse
        match = re.search(r'\{.*\}', reponse_ia, re.DOTALL)
        if match:
            json_str = match.group(0)
            donnees_extraites = json.loads(json_str)
            return donnees_extraites
        else:
            print("‚ö†Ô∏è Llama 3 n'a pas renvoy√© un format JSON valide.")
            return {}
            
    except Exception as e:
        print(f"‚ùå Erreur lors de l'appel √† Llama 3 : {e}")
        return {}